---
title: "Hands-on Exercise 3"
editor: visual
---

## 1 Overview

This hands-on exercise is on **geographical segmentation with spatially constrained clustering techniques**. The two major analysis covered are:

1.  Hierarchical cluster analysis

2.  Spatially constrained cluster analysis

### 1.1 The analytical question

In this case study, we are interested to **delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures**, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home.

## 2 Getting Ready

### 2.1 Load the required packages

The R packages needed are:

-   Spatial data handling

    -   **sf**, **rgdal** and **spdep**

-   Attribute data handling

    -   **tidyverse**, especially **readr**, **ggplot2** and **dplyr**

-   Choropleth mapping

    -   **tmap**

-   Multivariate data visualisation and analysis

    -   **coorplot**, **ggpubr**, and **heatmaply**

-   Cluster analysis

    -   **cluster**

    -   **ClustGeo**

```{r}
pacman::p_load(rgdal, spdep, tmap, sf, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse)
```

### 2.2 Import geospatial data (shapefile)

```{r}
shan_sf <- st_read(dsn = "data/geospatial", 
                   layer = "myanmar_township_boundaries") %>%
  filter(ST %in% c("Shan (East)", "Shan (North)", "Shan (South)"))
```

View content of shan_sf:

```{r}
shan_sf
```

We can also use `glimpse()` to reveal the data type of it's fields (as *shan_sf* is conformed to tidy framework).

```{r}
glimpse(shan_sf)
```

### 2.3 Import aspatial data (csv)

```{r}
ict <- read_csv ("data/aspatial/Shan-ICT.csv")
```

```{r}
summary(ict)
```

### 2.4 Derive new variables using dplyr package

The unit of measurement of the values is the number of household. However, using these values directly will result in bias by the underlying total number of households -- the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.

In order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.

```{r}
ict_derived <- ict %>%
  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>%
  mutate(`TV_PR` = `Television`/`Total households`*1000) %>%
  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>%
  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%
  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>%
  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %>%
  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,
         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,
         `TT_HOUSEHOLDS`=`Total households`,
         `RADIO`=`Radio`, `TV`=`Television`, 
         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,
         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) 
```

```{r}
ict_derived
```

## 3 Exploratory Data Analysis

### 3.1 EDA using statistical graphics

Histogram is used to identify overall distribution, which is right-skewed:

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")
```

Boxplot is used to detect outliers:

```{r}
ggplot(data=ict_derived, 
       aes(x=`RADIO`)) +
  geom_boxplot(color="black", 
               fill="light blue")
```

Next, we plot the distribution of the newly derived variables:

```{r}
radio <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

radio_box <- ggplot(data=ict_derived, 
       aes(x=`RADIO_PR`)) +
  geom_boxplot(color="black", 
               fill="light blue")

tv <- ggplot(data=ict_derived, 
             aes(x= `TV_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

tv_box <- ggplot(data=ict_derived, 
       aes(x=`TV_PR`)) +
  geom_boxplot(color="black", 
               fill="light blue")

llphone <- ggplot(data=ict_derived, 
             aes(x= `LLPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

llphone_box <- ggplot(data=ict_derived, 
             aes(x= `LLPHONE_PR`)) +
  geom_boxplot(color="black", 
                 fill="light blue")

mphone <- ggplot(data=ict_derived, 
             aes(x= `MPHONE_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

mphone_box <- ggplot(data=ict_derived, 
             aes(x= `MPHONE_PR`)) +
  geom_boxplot(color="black", 
                 fill="light blue")

computer <- ggplot(data=ict_derived, 
             aes(x= `COMPUTER_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

computer_box <- ggplot(data=ict_derived, 
             aes(x= `COMPUTER_PR`)) +
  geom_boxplot(color="black", 
                 fill="light blue")

internet <- ggplot(data=ict_derived, 
             aes(x= `INTERNET_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

internet_box <- ggplot(data=ict_derived, 
             aes(x= `INTERNET_PR`)) +
  geom_boxplot(color="black", 
                 fill="light blue")
```

```{r}
ggarrange(radio, radio_box, tv, tv_box, llphone, llphone_box, 
          mphone, mphone_box, computer, computer_box, internet, internet_box,
          ncol = 4, 
          nrow = 3)
```

### 3.2 EDA using choropleth map

#### Join geospatial data with aspatial data

```{r}
shan_sf <- left_join(shan_sf, 
                     ict_derived, 
                     by=c("TS_PCODE"="TS_PCODE"))
```

#### Plot choropleth map

We will create two choropleth maps, one for the total number of households (i.e.Â TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) to show that the number of household with radio is biased to the underlying total number of households at the townships.

```{r}
TT_HOUSEHOLDS.map <- tm_shape(shan_sf) + 
  tm_fill(col = "TT_HOUSEHOLDS",
          n = 5,
          style = "jenks", 
          title = "Total households") + 
  tm_borders(alpha = 0.5) 

RADIO.map <- tm_shape(shan_sf) + 
  tm_fill(col = "RADIO",
          n = 5,
          style = "jenks",
          title = "Number Radio ") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,
             asp=NA, ncol=2)
```

Notice that the choropleth maps above clearly show that townships with relatively larger number of households are also showing relatively higher number of radio ownership.

Next, we will plot the choropleth maps showing the dsitribution of total number of households and radio penetration rate by using the code chunk below.

```{r}
tm_shape(shan_sf) +
    tm_polygons(c("TT_HOUSEHOLDS", "RADIO_PR"),
                style="jenks") +
    tm_facets(sync = TRUE, ncol = 2) +
  tm_legend(legend.position = c("right", "bottom"))+
  tm_layout(outer.margins=0, asp=0)
```

There is no direct and obvious relationship as shown above, and thus the peneration rate is a better measure as it is not biased by the number of households.

## 4 Correlation Analysis

Before we perform cluster analysis, we should ensure that the cluster variables are not highly correlated.

```{r}
cluster_vars.cor = cor(ict_derived[,12:17])
corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

The correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both.

## 5 Hierarchy Cluster Analysis

### 5.1  Extract clustering variables

```{r}
cluster_vars <- shan_sf %>%
  st_set_geometry(NULL) %>%
  select("TS.x", "RADIO_PR", "TV_PR", "LLPHONE_PR", "MPHONE_PR", "COMPUTER_PR")
head(cluster_vars,10)
```

Note that we excluded INTERNET_PR as it is highly correlated with COMPUTER_PR.

Next, we need to change the rows by township name instead of row number by using the code chunk below:

```{r}
row.names(cluster_vars) <- cluster_vars$"TS.x"
head(cluster_vars,10)
```

Then, we delete the TS.x field:

```{r}
shan_ict <- select(cluster_vars, c(2:6))
head(shan_ict, 10)
```

### 5.2 Data Standardisation

#### Min-Max Standardisation

```{r}
shan_ict.std <- normalize(shan_ict)
summary(shan_ict.std)
```

#### Z-score Standardisation

```{r}
shan_ict.z <- scale(shan_ict)
describe(shan_ict.z)
```

#### Visualising Standardised Clustering Variables

```{r}
r <- ggplot(data=ict_derived, 
             aes(x= `RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue")

shan_ict_s_df <- as.data.frame(shan_ict.std)
s <- ggplot(data=shan_ict_s_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Min-Max Standardisation")

shan_ict_z_df <- as.data.frame(shan_ict.z)
z <- ggplot(data=shan_ict_z_df, 
       aes(x=`RADIO_PR`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  ggtitle("Z-score Standardisation")

ggarrange(r, s, z,
          ncol = 3,
          nrow = 1)
```

### 5.3 Computing proximity matrix

In R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using [*dist()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/dist.html) of R.

*dist()* supports six distance proximity calculations, they are: **euclidean, maximum, manhattan, canberra, binary and minkowski**. The default is *euclidean* proximity matrix.

The code chunk below is used to compute the proximity matrix using *euclidean* method.

```{r}
proxmat <- dist(shan_ict, method = 'euclidean') 
proxmat
```

### 5.4 Computing hierarchical clustering

In R, there are several packages provide hierarchical clustering function. In this hands-on exercise, [*hclust()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html) of R stats will be used.

*hclust()* employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).

The code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class **hclust** which describes the tree produced by the clustering process.

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

```{r}
plot(hclust_ward, cex = 0.6)
```

### 5.5 Selecting the optimal clustering algorithm

```{r}
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(shan_ict, method = x)$ac
}

map_dbl(m, ac)
```

The *agnes()* function functions like *hclus(),* and you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).

With reference to the output above, we can see that Ward\'s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward\'s method will be used.

### 5.6 Determining optimal clusters

There are [three](https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/) commonly used methods to determine the optimal clusters, they are:

-   [Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering))

-   [Average Silhouette Method](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub)

-   [Gap Statistic Method](https://statweb.stanford.edu/~gwalther/gap)

#### Gap Statistic Method

The [**gap statistic**](http://www.web.stanford.edu/~hastie/Papers/gap.pdf) compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.

```{r}
set.seed(12345)
gap_stat <- clusGap(shan_ict, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 10, 
                    B = 50)
# Print the result
print(gap_stat, method = "firstmax")
```

```{r}
fviz_gap_stat(gap_stat)
```

> Pick 6 clusters.

### 5.7 Interpreting the dendrograms

It\'s also possible to draw the dendrogram with a border around the selected clusters by using [*rect.hclust()*](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/rect.hclust.html) of R stats. The argument *border* is used to specify the border colors for the rectangles.

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```

### 5.8 Visually-driven hierarchical clustering analysis

```{r}
shan_ict_mat <- data.matrix(shan_ict)
heatmaply(normalize(shan_ict_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 6,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Shan State by ICT indicators",
          xlab = "ICT Indicators",
          ylab = "Townships of Shan State"
          )
```

### 5.9 Mapping the clusters formed

`cutree()` of R Base will be used in the code chunk below to derive a 6-cluster model.

```{r}
groups <- as.factor(cutree(hclust_ward, k=6))
```

```{r}
shan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

```{r}
qtm(shan_sf_cluster, "CLUSTER")
```

The choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.

## 6 Spatially Constrained Clustering - SKATER approach

### 6.1 Converting into SpatialPolygonsDataFrame

```{r}
shan_sp <- as_Spatial(shan_sf)
```

### 6.2 Computing Neighbour List

```{r}
shan.nb <- poly2nb(shan_sp)
summary(shan.nb)
```

```{r}
plot(shan_sp, 
     border=grey(.5))
plot(shan.nb, 
     coordinates(shan_sp), 
     col="blue", 
     add=TRUE)
```

Note that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.

### 6.3 Computing minimum spanning tree

#### Calculating edge costs

Next, [*nbcosts()*](https://r-spatial.github.io/spdep/reference/nbcosts.html) of **spdep** package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.

```{r}
lcosts <- nbcosts(shan.nb, shan_ict)
```

For each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.

Next, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed ***lcosts*** as the weights.

In order to achieve this, [*nb2listw()*](https://r-spatial.github.io/spdep/reference/nb2listw.html) of **spdep** package is used as shown in the code chunk below.

Note that we specify the *style* as **B** to make sure the cost values are not row-standardised.

```{r}
shan.w <- nb2listw(shan.nb, 
                   lcosts, 
                   style="B")
summary(shan.w)
```

#### Computing minimum spanning tree

```{r}
shan.mst <- mstree(shan.w)

class(shan.mst)

dim(shan.mst)
```

```{r}
head(shan.mst)
```

```{r}
plot(shan_sp, border=gray(.5))
plot.mst(shan.mst, 
         coordinates(shan_sp), 
         col="blue", 
         cex.lab=0.7, 
         cex.circles=0.005, 
         add=TRUE)
```

### 6.4 Computing spatially constrained clusters using SKATER method

The *skater()* takes three mandatory arguments: - the first two columns of the MST matrix (i.e.Â not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to **one less than the number of clusters**. So, the value specified is **not** the number of clusters, but the number of cuts in the graph, one less than the number of clusters.

```{r}
clust6 <- skater(edges = shan.mst[,1:2], 
                 data = shan_ict, 
                 method = "euclidean", 
                 ncuts = 5)
```

```{r}
str(clust6)
```

Check cluster assignment:

```{r}
ccs6 <- clust6$groups
ccs6
```

Find out how many observations are in each cluster:

```{r}
table(ccs6)
```

Plot the pruned tree that shows the five clusters on top of the townshop area.

```{r}
plot(shan_sp, border=gray(.5))
plot(clust6, 
     coordinates(shan_sp), 
     cex.lab=.7,
     groups.colors=c("red","green","blue", "brown", "pink"),
     cex.circles=0.005, 
     add=TRUE)
```

### 6.5 Visualising the clusters in choropleth map

```{r}
groups_mat <- as.matrix(clust6$groups)
shan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
qtm(shan_sf_spatialcluster, "SP_CLUSTER")
```

```{r}
hclust.map <- qtm(shan_sf_cluster,
                  "CLUSTER") + 
  tm_borders(alpha = 0.5) 

shclust.map <- qtm(shan_sf_spatialcluster,
                   "SP_CLUSTER") + 
  tm_borders(alpha = 0.5) 

tmap_arrange(hclust.map, shclust.map,
             asp=NA, ncol=2)
```
